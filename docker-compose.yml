services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "${FRONTEND_PORT}:80"
    depends_on:
      - api
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:14
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U videotranscriber"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  api:
    build:
      context: .
      dockerfile: services/api_service/Dockerfile
    volumes:
      - ./data:/app/data
      - ./common:/app/common
      - ./services/api_service:/app/api_service
      - ./services/transcription_service:/app/transcription_service
      - ./services/summarization_service:/app/summarization_service
      - ./services/translation_service:/app/translation_service
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - LLM_HOST=${LLM_HOST}
      - LLM_MODEL=${LLM_MODEL}
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - SKIP_DB_INIT=${SKIP_DB_INIT}
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - VIDEO_DIRS=${VIDEO_DIRS}
    ports:
      - "${API_PORT}:8000"
    command:
      [
        "sh",
        "-c",
        "pip install pika==1.3.2 && pip install -e /app/common && PYTHONPATH=/app python -m api.main",
      ]
    working_dir: /app/api_service
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  transcription-worker:
    build:
      context: .
      dockerfile: services/transcription_service/Dockerfile
    volumes:
      - ./data:/app/data
      - ./common:/app/common
      - ./services/transcription_service:/app/transcription_service
    depends_on:
      postgres:
        condition: service_healthy
      api:
        condition: service_started
      rabbitmq:
        condition: service_healthy
    environment:
      - API_URL=${API_URL}
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - MAX_WORKERS=${MAX_WORKERS}
      - VIDEO_DIRS=${VIDEO_DIRS}
      - HF_TOKEN=${HF_TOKEN}
    command:
      [
        "sh",
        "-c",
        "pip install -e /app/common && PYTHONPATH=/app python -m transcription.main --max-workers=${MAX_WORKERS}",
      ]
    working_dir: /app/transcription_service
    restart: unless-stopped
    # deploy:
    #   resources:
    #     limits:
    #       memory: 16G
    #       cpus: "7.0"
    #     reservations:
    #       memory: 8G
    #       cpus: "7.0"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  summarization-worker:
    build:
      context: .
      dockerfile: services/summarization_service/Dockerfile
    volumes:
      - ./data:/app/data
      - ./common:/app/common
      - ./services/summarization_service:/app/summarization_service
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_healthy
      api:
        condition: service_started
      rabbitmq:
        condition: service_healthy
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - LLM_HOST=${LLM_HOST}
      - LLM_MODEL=${LLM_MODEL}
      - API_URL=${API_URL}
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
    command:
      [
        "sh",
        "-c",
        "pip install pika==1.3.2 && pip install -e /app/common && PYTHONPATH=/app python -m summarization.main",
      ]
    working_dir: /app/summarization_service
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  translation-worker:
    build:
      context: .
      dockerfile: services/translation_service/Dockerfile
    volumes:
      - ./data:/app/data
      - ./common:/app/common
      - ./services/translation_service:/app/translation_service
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_healthy
      api:
        condition: service_started
      rabbitmq:
        condition: service_healthy
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - LLM_HOST=${LLM_HOST}
      - LLM_MODEL=${LLM_MODEL}
      - API_URL=${API_URL}
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
    command:
      [
        "sh",
        "-c",
        "pip install pika==1.3.2 && pip install -e /app/common && PYTHONPATH=/app python -m translation.main",
      ]
    working_dir: /app/translation_service
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ollama:
    image: ollama/ollama
    volumes:
      - ./ollama-data:/root/.ollama
      - ./ollama-entrypoint.sh:/ollama-entrypoint.sh
    ports:
      - "${OLLAMA_PORT}:11434"
    restart: unless-stopped
    entrypoint: ["/ollama-entrypoint.sh"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s # Give time for the model to be pulled
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  watcher:
    build:
      context: .
      dockerfile: services/watcher_service/Dockerfile
    volumes:
      - ./data:/app/data
      - ./common:/app/common
      - ./services/api_service:/app/api_service
      - ./services/watcher_service:/app/watcher_service
    depends_on:
      postgres:
        condition: service_healthy
      api:
        condition: service_started
      rabbitmq:
        condition: service_healthy
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - API_URL=${API_URL}
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - VIDEO_DIRS=${VIDEO_DIRS}
    command:
      [
        "sh",
        "-c",
        "pip install pika==1.3.2 && pip install -e /app/common && PYTHONPATH=/app python -m watcher.watcher",
      ]
    working_dir: /app/watcher_service
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  rabbitmq:
    image: rabbitmq:3-management
    ports:
      - "${RABBITMQ_PORT}:5672" # AMQP protocol port
      - "${RABBITMQ_MANAGEMENT_PORT}:15672" # Management UI port
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS}
      # Configure frame size limits to prevent frame_too_large errors
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit frame_max 131072
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
        reservations:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres-data:
